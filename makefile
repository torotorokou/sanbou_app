## =============================================================
## Makefile : sanbou_app å…¨ç’°å¢ƒçµ±åˆç®¡ç†ãƒ„ãƒ¼ãƒ«
## =============================================================
##
## ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
##    MAKEFILE_QUICKREF.md           - ã‚¯ã‚¤ãƒƒã‚¯ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹
##    docs/infrastructure/MAKEFILE_GUIDE.md - è©³ç´°ã‚¬ã‚¤ãƒ‰
##
## ğŸš€ ã‚ˆãä½¿ã†ã‚³ãƒãƒ³ãƒ‰
##    make up ENV=local_dev          - ç’°å¢ƒèµ·å‹•
##    make down ENV=local_dev        - ç’°å¢ƒåœæ­¢
##    make logs ENV=local_dev S=xxx  - ãƒ­ã‚°ç¢ºèª
##    make al-up-env ENV=local_dev   - DBãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ–°è¦ç’°å¢ƒã¯è‡ªå‹•ã§baselineé©ç”¨ï¼‰
##    make backup ENV=local_dev      - ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
##
## ğŸ†• æ–°è¦ç’°å¢ƒæ§‹ç¯‰ï¼ˆbaselineâ†’rolesâ†’alembic ã‚’è‡ªå‹•å®Ÿè¡Œï¼‰
##    make al-up-env ENV=vm_stg      - ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒï¼ˆåˆå›ã§ã‚‚è‡ªå‹•ã§å™¨ä½œæˆï¼‰
##    make al-up-env ENV=vm_prod FORCE=1  - æœ¬ç•ªç’°å¢ƒï¼ˆåˆå›ã®ã¿FORCE=1å¿…é ˆï¼‰
##
## ğŸŒ ç’°å¢ƒ (ENV)
##    local_dev  - ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºï¼ˆè‡ªå‹•ãƒ“ãƒ«ãƒ‰ï¼‰
##    local_demo - ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¢
##    vm_stg     - GCP VM ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ï¼ˆArtifact Registryï¼‰
##    vm_prod    - GCP VM æœ¬ç•ªï¼ˆArtifact Registryï¼‰
##
## âš ï¸ VMç’°å¢ƒã§ã®æ³¨æ„
##    - vm_stg ã¨ vm_prod ã¯åŒæ™‚èµ·å‹•ä¸å¯ï¼ˆãƒãƒ¼ãƒˆ80ç«¶åˆï¼‰
##    - VMç’°å¢ƒã§ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰å¾Œ pull ã—ã¦ä½¿ç”¨
##    - æœ¬ç•ªãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‰ã«å¿…ãšãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å–å¾—
##
## =============================================================

## ã‚°ãƒ­ãƒ¼ãƒãƒ«ç’°å¢ƒå¤‰æ•°
## -------------------------------------------------------------
ENV ?= local_dev
ENV := $(strip $(ENV))
DC  := docker compose
BUILDKIT ?= 1
PROGRESS ?= plain

## ============================================================
## ç’°å¢ƒãƒãƒƒãƒ”ãƒ³ã‚° (Environment Mapping)
##   - ENV ã«å¿œã˜ã¦:
##     - ä½¿ç”¨ã™ã‚‹ docker-compose.yml
##     - ä½¿ç”¨ã™ã‚‹ .env ãƒ•ã‚¡ã‚¤ãƒ«
##     - health check URL
##     - build æœ‰ç„¡
##
## â˜… nginx å‹•ä½œç¢ºèªï¼ˆHTTP ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆä¿®æ­£å¾Œã®ç¢ºèªæ‰‹é †ï¼‰:
##
##   ã€vm_stg ã§ã®ç¢ºèªã€‘
##   VM å†…ã§:
##     curl -I http://localhost/health    # â†’ HTTP/1.1 200 OK
##     curl -I http://localhost/          # â†’ HTTP/1.1 200 OK, Content-Type: text/html
##                                        #    â€» Location: https://... ãŒå«ã¾ã‚Œãªã„ã“ã¨
##   ãƒ­ãƒ¼ã‚«ãƒ« PC ã‹ã‚‰ (Tailscale çµŒç”±):
##     http://100.119.243.45/             # â†’ React ç”»é¢ãŒè¡¨ç¤ºã•ã‚Œã€https ã¸ã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆãªã—
##
##   ã€vm_prod ã§ã®ç¢ºèªã€‘
##   VM å†…ã§:
##     curl -I http://localhost/health    # â†’ HTTP/1.1 200 OK
##     curl -I http://localhost/          # â†’ HTTP/1.1 200 OK, Content-Type: text/html
##                                        #    â€» Location: https://localhost/ ãŒå«ã¾ã‚Œãªã„ã“ã¨
##   GCP LB + IAP çµŒç”±:
##     https://sanbou-app.jp/             # â†’ React ç”»é¢ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨
##                                        #    â€» HTTPS ã¯ LB å´ã§çµ‚ç«¯ã€VM ã¯ HTTP(80) ã®ã¿
## ============================================================
ENV_CANON := $(ENV)

# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®è­¦å‘Šã¨è‡ªå‹•å¤‰æ›
ifeq ($(ENV),dev)
	$(warning [compat] ENV=dev ã¯éæ¨å¥¨ã§ã™ã€‚ENV=local_dev ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„)
	ENV_CANON := local_dev
endif
ifeq ($(ENV),stg)
	$(warning [compat] ENV=stg ã¯éæ¨å¥¨ã§ã™ã€‚ENV=vm_stg ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„)
	ENV_CANON := vm_stg
endif
ifeq ($(ENV),prod)
	$(warning [compat] ENV=prod ã¯éæ¨å¥¨ã§ã™ã€‚ENV=vm_prod ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„)
	ENV_CANON := vm_prod
endif
# local_stg / local_prod ã¯å»ƒæ­¢æ¸ˆã¿
ifeq ($(ENV),local_stg)
	$(error ENV=local_stg ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸã€‚ENV=vm_stg ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„)
endif
ifeq ($(ENV),local_prod)
	$(error ENV=local_prod ã¯å»ƒæ­¢ã•ã‚Œã¾ã—ãŸã€‚ENV=vm_prod ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„)
endif

# å…±é€š .env ã¯å¸¸ã«ã“ã‚Œ
ENV_FILE_COMMON := env/.env.common
# ENV å€‹åˆ¥ï¼ˆå¾Œã§ ENV_CANON ã«ã‚ˆã£ã¦ä¸Šæ›¸ãï¼‰
ENV_FILE        := env/.env.$(ENV)

# ENV ã”ã¨ã® compose / env / health
ifeq ($(ENV_CANON),local_dev)
	ENV_FILE      := env/.env.local_dev
	COMPOSE_FILES := -f docker/docker-compose.dev.yml
	HEALTH_URL    := http://localhost:8001/health
else ifeq ($(ENV_CANON),vm_stg)
	ENV_FILE      := env/.env.vm_stg
	COMPOSE_FILES := -f docker/docker-compose.stg.yml
	HEALTH_URL    := http://100.64.0.1/health
else ifeq ($(ENV_CANON),vm_prod)
	ENV_FILE      := env/.env.vm_prod
	COMPOSE_FILES := -f docker/docker-compose.prod.yml
	HEALTH_URL    := https://sanbou-app.jp/health
else ifeq ($(ENV_CANON),local_demo)
	ENV_FILE      := env/.env.local_demo
	COMPOSE_FILES := -f docker/docker-compose.local_demo.yml
	HEALTH_URL    := http://localhost:8013/health
else
	$(error Unsupported ENV: $(ENV). Supported: local_dev, vm_stg, vm_prod, local_demo)
endif

# vm_stg / vm_prod ã¯ Artifact Registry ã‹ã‚‰ã‚¤ãƒ¡ãƒ¼ã‚¸ pull ã®ã¿ (--build ãªã—)
ifeq ($(ENV_CANON),vm_stg)
	UP_BUILD_FLAGS :=
else ifeq ($(ENV_CANON),vm_prod)
	UP_BUILD_FLAGS :=
else
	UP_BUILD_FLAGS := --build
endif

SECRETS_FILE      := secrets/.env.$(ENV).secrets
# secrets ãƒ•ã‚¡ã‚¤ãƒ«ã¯å­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ --env-file ã«è¼‰ã›ã‚‹
COMPOSE_ENV_ARGS  := --env-file $(ENV_FILE_COMMON) --env-file $(ENV_FILE) \
                     $(if $(wildcard $(SECRETS_FILE)),--env-file $(SECRETS_FILE),)
COMPOSE_FILE_LIST := $(strip $(subst -f ,,$(COMPOSE_FILES)))
DC_FULL           := $(DC) $(COMPOSE_ENV_ARGS) -p $(ENV) $(COMPOSE_FILES)

.PHONY: check up down logs ps restart rebuild health config \
	backup restore-from-dump restore-from-sql dev-with-nginx pull

## ============================================================
## åŸºæœ¬æ“ä½œ (docker compose up / down ãªã©)
## ============================================================
check:
	@for f in $(COMPOSE_FILE_LIST); do \
	  if [ ! -f "$$f" ]; then echo "[error] compose file $$f not found"; exit 1; fi; \
	done
	@if [ ! -f "$(ENV_FILE_COMMON)" ]; then echo "[error] $(ENV_FILE_COMMON) not found"; exit 1; fi
	@if [ ! -f "$(ENV_FILE)" ]; then echo "[error] $(ENV_FILE) not found"; exit 1; fi

up: check
	@echo "[info] UP (ENV=$(ENV))"
	@echo "[debug] ENV=$(ENV) ENV_CANON=$(ENV_CANON)"
	@echo "[debug] COMPOSE_FILES=$(COMPOSE_FILES)"
	@echo "[debug] ENV_FILE=$(ENV_FILE)"
	@echo "[debug] COMPOSE_ENV_ARGS=$(COMPOSE_ENV_ARGS)"
	@echo "[debug] UP_BUILD_FLAGS=$(UP_BUILD_FLAGS)"
	@echo "[debug] DC_FULL=$(DC_FULL)"
	@if [ "$(PULL)" = "1" ]; then \
		if [ "$(ENV_CANON)" = "vm_stg" ] || [ "$(ENV_CANON)" = "vm_prod" ]; then \
			echo "[info] PULL=1 and ENV_CANON=$(ENV_CANON) -> pulling images before up"; \
			$(DC_FULL) pull; \
		fi; \
	fi; \
	DOCKER_BUILDKIT=$(BUILDKIT) BUILDKIT_PROGRESS=$(PROGRESS) \
	$(DC_FULL) up -d $(UP_BUILD_FLAGS) --remove-orphans
	@echo "[ok] up done"

down:
	@echo "[info] DOWN (ENV=$(ENV))"
	@CIDS="$$( $(DC) -p $(ENV) ps -q | wc -l )"; \
	if [ "$$CIDS" -gt 0 ]; then \
	  $(DC) -p $(ENV) down --remove-orphans; \
	else echo "[info] no running containers"; fi

logs:
	$(DC) -p $(ENV) logs -f $(S)

ps:
	$(DC) -p $(ENV) ps

restart:
	$(MAKE) down ENV=$(ENV)
	$(MAKE) up   ENV=$(ENV)

## PULL: control whether to run `docker compose pull` before `up`
## Default depends on ENV_CANON (use ?= so user-specified value takes precedence)
ifeq ($(ENV_CANON),vm_stg)
PULL ?= 1
else ifeq ($(ENV_CANON),vm_prod)
PULL ?= 1
else
PULL ?= 0
endif
BUILD_PULL_FLAG := $(if $(filter 1,$(PULL)),--pull,)
NO_CACHE ?= 0
BUILD_NO_CACHE_FLAG := $(if $(filter 1,$(NO_CACHE)),--no-cache,)

rebuild: check
	@echo "[info] rebuild ENV=$(ENV)"
	$(MAKE) down ENV=$(ENV)
	DOCKER_BUILDKIT=$(BUILDKIT) BUILDKIT_PROGRESS=$(PROGRESS) \
	$(DC_FULL) build $(BUILD_PULL_FLAG) --no-cache
	DOCKER_BUILDKIT=$(BUILDKIT) BUILDKIT_PROGRESS=$(PROGRESS) \
	$(DC_FULL) up -d --remove-orphans
	@echo "[ok] rebuild done"

pull: check
	@echo "[info] Pulling images (ENV=$(ENV))"
	$(DC_FULL) pull

health:
	@echo "[info] health check -> $(HEALTH_URL)"
	@curl -I "$(HEALTH_URL)" || echo "[warn] curl failed"

config: check
	$(DC_FULL) config

## ============================================================
## Worker ç®¡ç†ï¼ˆå€‹åˆ¥èµ·å‹•ãƒ»åœæ­¢ãƒ»ãƒ­ã‚°ç¢ºèªï¼‰
## ============================================================
## ä½¿ã„æ–¹:
##   make worker-up ENV=local_dev WORKER=inbound_forecast_worker
##   make worker-logs ENV=local_dev WORKER=inbound_forecast_worker
##   make worker-restart ENV=local_dev WORKER=inbound_forecast_worker
##   make worker-down ENV=local_dev WORKER=inbound_forecast_worker
## ============================================================
WORKER ?= inbound_forecast_worker

worker-up: check
	@echo "[info] Starting $(WORKER) in $(ENV_CANON)..."
	DOCKER_BUILDKIT=$(BUILDKIT) BUILDKIT_PROGRESS=$(PROGRESS) \
	$(DC_FULL) up -d $(UP_BUILD_FLAGS) $(WORKER)
	@echo "[ok] $(WORKER) started"

worker-down: check
	@echo "[info] Stopping $(WORKER) in $(ENV_CANON)..."
	$(DC_FULL) stop $(WORKER)
	$(DC_FULL) rm -f $(WORKER)
	@echo "[ok] $(WORKER) stopped"

worker-logs: check
	$(DC_FULL) logs -f --tail=100 $(WORKER)

worker-restart: check
	@echo "[info] Restarting $(WORKER) in $(ENV_CANON)..."
	$(DC_FULL) restart $(WORKER)
	@echo "[ok] $(WORKER) restarted"

## ============================================================
## é–‹ç™ºç’°å¢ƒï¼šnginx ä»˜ãèµ·å‹• (æœ¬ç•ªã«è¿‘ã„æ§‹æˆã§ã®é–‹ç™ºãƒ»æ¤œè¨¼)
## ============================================================
## ä½¿ã„æ–¹:
##   make dev-with-nginx        # nginx ä»˜ãã§èµ·å‹•
##   make down ENV=local_dev    # åœæ­¢
##
## ã‚¢ã‚¯ã‚»ã‚¹:
##   http://localhost:8080      # nginx çµŒç”± (æœ¬ç•ªã¨åŒæ§˜ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
##   http://localhost:5173      # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç›´æ¥
##   http://localhost:8001      # ai_api ç›´æ¥
##   http://localhost:8002      # core_api ç›´æ¥
## ============================================================
dev-with-nginx:
	@echo "[info] Starting local_dev with nginx (profile: with-nginx)"
	@echo "[info] Access via: http://localhost:8080 (nginx)"
	DOCKER_BUILDKIT=$(BUILDKIT) BUILDKIT_PROGRESS=$(PROGRESS) \
	docker compose -f docker/docker-compose.dev.yml -p local_dev \
	  --env-file env/.env.common --env-file env/.env.local_dev \
	  $(if $(wildcard secrets/.env.local_dev.secrets),--env-file secrets/.env.local_dev.secrets,) \
	  --profile with-nginx up -d --build --remove-orphans
	@echo "[ok] Dev environment with nginx started"
	@echo "[info] Check health: curl http://localhost:8080/health"

## ============================================================
## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— / ãƒªã‚¹ãƒˆã‚¢ï¼ˆç’°å¢ƒåˆ¥è‡ªå‹•å¯¾å¿œï¼‰
## ============================================================
## æ³¨æ„:
##   - POSTGRES_USER ã¨ POSTGRES_DB ã¯å„ç’°å¢ƒã® .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è‡ªå‹•å–å¾—
##   - local_dev: myuser / sanbou_dev
##   - vm_stg: sanbou_app_stg / sanbou_stg
##   - vm_prod: sanbou_app_prod / sanbou_prod
## ============================================================
DATE        := $(shell date +%F_%H%M%S)
BACKUP_DIR  ?= /mnt/c/Users/synth/Desktop/backups
PG_SERVICE  ?= db

backup:
	@echo "[info] logical backup (pg_dump) ENV=$(ENV)"
	@mkdir -p "$(BACKUP_DIR)"
	$(DC_FULL) exec -T $(PG_SERVICE) sh -c '\
	  pg_dump -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" \
	    --format=custom --file=/tmp/backup.dump'
	$(DC_FULL) cp $(PG_SERVICE):/tmp/backup.dump \
	  "$(BACKUP_DIR)/$(ENV)_$(DATE).dump"
	@$(DC_FULL) exec -T $(PG_SERVICE) rm -f /tmp/backup.dump || true
	@echo "[ok] backup -> $(BACKUP_DIR)/$(ENV)_$(DATE).dump"

.PHONY: restore-from-dump
DUMP ?= backups/sanbou_dev_2025-12-03.dump

restore-from-dump: check
	@if [ ! -f "$(DUMP)" ]; then \
	  echo "[error] dump file not found: $(DUMP)"; exit 1; \
	fi
	@echo "[info] Restoring $(DUMP) (ENV=$(ENV))"
	@echo "[info] Using container's POSTGRES_USER and POSTGRES_DB environment variables"
	$(DC_FULL) cp "$(DUMP)" $(PG_SERVICE):/tmp/restore.dump
	$(DC_FULL) exec -T $(PG_SERVICE) sh -c '\
	  dropdb  -U "$$POSTGRES_USER" --if-exists --force "$${POSTGRES_DB:-postgres}" && \
	  createdb -U "$$POSTGRES_USER" "$${POSTGRES_DB:-postgres}" && \
	  pg_restore -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" --no-owner --no-acl /tmp/restore.dump \
	'
	@$(DC_FULL) exec -T $(PG_SERVICE) rm -f /tmp/restore.dump || true
	@echo "[ok] restore-from-dump completed"

## -------------------------------------------------------------
## SQL ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.sqlï¼‰ã‹ã‚‰ã®ãƒªã‚¹ãƒˆã‚¢ï¼ˆåˆ¥ç’°å¢ƒã¸ã®é©ç”¨ãªã©ï¼‰
##   ä½¿ã„æ–¹:
##     make restore-from-sql ENV=local_demo \
##          SQL=backups/pg_all_2025-12-03.sql
## -------------------------------------------------------------
.PHONY: restore-from-sql
SQL ?=

restore-from-sql: check
	@if [ -z "$(SQL)" ]; then \
	  echo "[error] SQL parameter is required."; \
	  echo "Usage: make restore-from-sql ENV=$(ENV) SQL=backups/xxx.sql"; \
	  exit 1; \
	fi
	@if [ ! -f "$(SQL)" ]; then \
	  echo "[error] SQL file not found: $(SQL)"; exit 1; \
	fi
	@echo "[info] Restoring SQL $(SQL) (ENV=$(ENV))"
	@echo "[info] Using container's POSTGRES_USER and POSTGRES_DB environment variables"
	@cat "$(SQL)" | $(DC_FULL) exec -T $(PG_SERVICE) sh -c '\
	  psql -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}"'
	@echo "[ok] restore-from-sql completed"

## ============================================================
## DB Baseline: ã‚¹ã‚­ãƒ¼ãƒãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã®è‡ªå‹•é©ç”¨ï¼ˆå†ªç­‰ï¼‰
## ============================================================
## ç›®çš„:
##   - æ–°è¦ç’°å¢ƒã§ schema_baseline.sql ã‚’è‡ªå‹•é©ç”¨ã—ã¦ã‚¹ã‚­ãƒ¼ãƒ/ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
##   - marker table (public.schema_baseline_meta) ã§é©ç”¨æ¸ˆã¿åˆ¤å®š
##   - vm_prod ã§ã¯èª¤é©ç”¨é˜²æ­¢ã®ãŸã‚ FORCE=1 å¿…é ˆ
##
## ä½¿ã„æ–¹:
##   make db-ensure-baseline-env ENV=vm_stg
##   make db-ensure-baseline-env ENV=vm_prod FORCE=1
##
## æ³¨æ„:
##   - å¯¾è±¡ENVã¯å…ˆã« `make up ENV=...` ã§èµ·å‹•ã—ã¦ãŠãã“ã¨
##   - schema_baseline.sql ã« alembic_version ãŒå«ã¾ã‚Œã¦ã„ãŸã‚‰ã‚¨ãƒ©ãƒ¼
##   - ä¸­é€”åŠç«¯ãªçŠ¶æ…‹ï¼ˆstgã ã‘å­˜åœ¨ç­‰ï¼‰ã¯ãƒœãƒªãƒ¥ãƒ¼ãƒ å‰Šé™¤æ¨å¥¨
## ============================================================
.PHONY: db-ensure-baseline-env

BASELINE_SQL := app/backend/core_api/migrations_v2/sql/schema_baseline.sql

db-ensure-baseline-env: check
	@echo "[info] Checking baseline status (ENV=$(ENV))"
	@if [ ! -f "$(BASELINE_SQL)" ]; then \
	  echo "[error] $(BASELINE_SQL) not found"; exit 1; \
	fi
	@if grep -q "alembic_version" "$(BASELINE_SQL)"; then \
	  echo "[error] $(BASELINE_SQL) contains 'alembic_version' - this must be removed!"; exit 1; \
	fi
	@echo "[info] Waiting for database to be ready..."
	@for i in 1 2 3 4 5 6 7 8 9 10; do \
	  if $(DC_FULL) exec -T $(PG_SERVICE) sh -c 'pg_isready -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" > /dev/null 2>&1'; then \
	    echo "[info] Database is ready"; break; \
	  fi; \
	  echo "[info] Waiting for database... (attempt $$i/10)"; \
	  sleep 2; \
	done
	@MARKER_EXISTS=$$($(DC_FULL) exec -T $(PG_SERVICE) sh -c 'psql -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" -tAc "SELECT EXISTS(SELECT 1 FROM information_schema.tables WHERE table_schema='"'"'public'"'"' AND table_name='"'"'schema_baseline_meta'"'"');"'); \
	if [ "$$MARKER_EXISTS" = "t" ]; then \
	  echo "[info] Baseline already applied (marker table exists)"; \
	else \
	  echo "[info] Baseline not applied, checking for partial state..."; \
	  STG_EXISTS=$$($(DC_FULL) exec -T $(PG_SERVICE) sh -c 'psql -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" -tAc "SELECT EXISTS(SELECT 1 FROM information_schema.schemata WHERE schema_name='"'"'stg'"'"');"'); \
	  if [ "$$STG_EXISTS" = "t" ]; then \
	    echo "[error] stg schema exists but marker table is missing!"; \
	    echo "[error] This indicates a partial/broken state. Please run:"; \
	    echo "        make down ENV=$(ENV)"; \
	    echo "        docker volume rm $(ENV)_db_data"; \
	    echo "        make up ENV=$(ENV)"; \
	    exit 1; \
	  fi; \
	  if [ "$(ENV_CANON)" = "vm_prod" ] && [ "$(FORCE)" != "1" ]; then \
	    echo "[error] vm_prod requires FORCE=1 to apply baseline (prevent accidents)"; exit 1; \
	  fi; \
	  echo "[info] Applying baseline schema..."; \
	  BASELINE_SHA256=$$(sha256sum "$(BASELINE_SQL)" | awk '{print $$1}'); \
	  $(DC_FULL) cp $(BASELINE_SQL) $(PG_SERVICE):/tmp/schema_baseline.sql; \
	  $(DC_FULL) exec -T $(PG_SERVICE) sh -c '\
	    psql -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" \
	         -v ON_ERROR_STOP=1 \
	         -f /tmp/schema_baseline.sql'; \
	  $(DC_FULL) exec -T $(PG_SERVICE) sh -c '\
	    psql -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" -c \
	      "CREATE TABLE IF NOT EXISTS public.schema_baseline_meta( \
	         id bigserial primary key, \
	         applied_at timestamptz not null default now(), \
	         baseline_path text not null, \
	         baseline_sha256 text not null \
	       ); \
	       INSERT INTO public.schema_baseline_meta(baseline_path, baseline_sha256) \
	       VALUES ('"'"'$(BASELINE_SQL)'"'"', '"'"''"$$BASELINE_SHA256"''"'"');"'; \
	  $(DC_FULL) exec -T $(PG_SERVICE) rm -f /tmp/schema_baseline.sql; \
	  echo "[ok] Baseline applied successfully"; \
	fi

## ============================================================
## DB Bootstrap: Roles & Permissions (å†ªç­‰ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
## ============================================================
## ç›®çš„:
##   - app_readonly ãƒ­ãƒ¼ãƒ«ã¨åŸºæœ¬æ¨©é™ã‚’å†ªç­‰çš„ã«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
##   - Alembic ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œå‰ã«æ¯å›å®Ÿè¡Œå¯èƒ½ï¼ˆå†ªç­‰ãªã®ã§å®‰å…¨ï¼‰
##
## ä½¿ã„æ–¹:
##   make db-bootstrap-roles-env ENV=local_dev
##   make db-bootstrap-roles-env ENV=vm_stg
##   make db-bootstrap-roles-env ENV=vm_prod
##
## æ³¨æ„:
##   - å¯¾è±¡ENVã¯å…ˆã« `make up ENV=...` ã§èµ·å‹•ã—ã¦ãŠãã“ã¨
##   - VMä¸Šã§å®Ÿè¡Œã™ã‚‹å ´åˆã€DBã‚³ãƒ³ãƒ†ãƒŠå†…ã®ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚
##     ãƒ›ã‚¹ãƒˆå´ã®ç’°å¢ƒå¤‰æ•°ã«ã¯ä¾å­˜ã—ãªã„
## ============================================================
.PHONY: db-bootstrap-roles-env

BOOTSTRAP_ROLES_SQL ?= scripts/db/bootstrap_roles.sql

db-bootstrap-roles-env: check
	@echo "[info] Bootstrap DB roles and permissions (ENV=$(ENV))"
	@if [ ! -f "$(BOOTSTRAP_ROLES_SQL)" ]; then \
	  echo "[error] $(BOOTSTRAP_ROLES_SQL) not found"; exit 1; \
	fi
	@echo "[info] Copying SQL to container..."
	$(DC_FULL) cp $(BOOTSTRAP_ROLES_SQL) $(PG_SERVICE):/tmp/bootstrap_roles.sql
	@echo "[info] Executing bootstrap SQL..."
	$(DC_FULL) exec -T $(PG_SERVICE) sh -c '\
	  psql -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" \
	       -v ON_ERROR_STOP=0 \
	       -f /tmp/bootstrap_roles.sql'
	@echo "[info] Cleaning up temporary file..."
	-$(DC_FULL) exec -T $(PG_SERVICE) rm -f /tmp/bootstrap_roles.sql
	@echo "[ok] db-bootstrap-roles-env completed"

## ============================================================
## Alembicï¼ˆé–‹ç™ºç’°å¢ƒ local_dev å‰æï¼‰
## ============================================================
.PHONY: al-rev al-rev-auto al-up al-down al-cur al-hist al-heads al-stamp \
        al-dump-schema-current al-init-from-schema \
        al-up-env al-down-env al-cur-env al-hist-env al-heads-env al-stamp-env

# Alembic ã¯åŸºæœ¬ local_dev ã§å®Ÿè¡Œã™ã‚‹æƒ³å®šï¼ˆå¾“æ¥ã©ãŠã‚Šå›ºå®šï¼‰
ALEMBIC_DC := docker compose -f docker/docker-compose.dev.yml -p local_dev
ALEMBIC    := $(ALEMBIC_DC) exec core_api alembic -c /backend/migrations/alembic.ini

MSG    ?= update schema
REV_ID ?= $(shell date +%Y%m%d_%H%M%S%3N)  # ä¾‹: 20251104_153045123

al-rev:
	@echo "[al-rev] REV_ID=$(REV_ID) MSG=$(MSG)"
	$(ALEMBIC) revision -m "$(MSG)" --rev-id $(REV_ID)

al-rev-auto:
	@echo "[al-rev-auto] REV_ID=$(REV_ID) MSG=$(MSG)"
	$(ALEMBIC) revision --autogenerate -m "$(MSG)" --rev-id $(REV_ID)

al-up:
	@echo "[info] Running DB bootstrap before Alembic migration (local_dev)..."
	@$(MAKE) db-bootstrap-roles-env ENV=local_dev
	@echo "[info] Starting Alembic migration..."
	$(ALEMBIC) upgrade head

al-down:
	$(ALEMBIC) downgrade -1

al-cur:
	$(ALEMBIC) current

al-hist:
	$(ALEMBIC) history

al-heads:
	$(ALEMBIC) heads

# æ—¢å­˜ DB ã«ã€Œé©ç”¨æ¸ˆã¿å°ã€ã‚’ä»˜ã‘ã‚‹
# ä½¿ã„æ–¹: make al-stamp REV=20251104_153045123
al-stamp:
	$(ALEMBIC) stamp $(REV)

## ------------------------------------------------------------
## Alembicï¼ˆENVã«è¿½å¾“ã—ã¦é©ç”¨ã™ã‚‹ç‰ˆï¼švm_stg / vm_prod ã§ã‚‚ä½¿ãˆã‚‹ï¼‰
## â€» migrations_v2 ã‚’ä½¿ç”¨ï¼ˆlegacy migrations/ ã¯å‰Šé™¤æ¸ˆã¿ï¼‰
## ä½¿ã„æ–¹:
##   make al-cur-env ENV=vm_stg
##   make al-up-env  ENV=vm_stg
##   make al-up-env  ENV=vm_prod
## ------------------------------------------------------------
ALEMBIC_INI ?= /backend/migrations_v2/alembic.ini
ALEMBIC_ENV := $(DC_FULL) exec core_api alembic -c $(ALEMBIC_INI)

al-up-env: check
	@echo "[info] Ensuring baseline schema exists..."
	@$(MAKE) db-ensure-baseline-env ENV=$(ENV) FORCE=$(FORCE)
	@echo "[info] Running DB roles bootstrap..."
	@$(MAKE) db-bootstrap-roles-env ENV=$(ENV)
	@echo "[info] Starting Alembic migration..."
	$(ALEMBIC_ENV) upgrade head

al-down-env: check
	$(ALEMBIC_ENV) downgrade -1

al-cur-env: check
	$(ALEMBIC_ENV) current

al-hist-env: check
	$(ALEMBIC_ENV) history

al-heads-env: check
	$(ALEMBIC_ENV) heads

# æ—¢å­˜ DB ã«ã€Œé©ç”¨æ¸ˆã¿å°ã€ã‚’ä»˜ã‘ã‚‹ï¼ˆENVè¿½å¾“ï¼‰
# ä½¿ã„æ–¹: make al-stamp-env ENV=vm_prod REV=<HEAD_REVISION>
al-stamp-env: check
	$(ALEMBIC_ENV) stamp $(REV)

## ============================================================
## Alembic: Schema Dump & Init (local_dev å‰æ)
## â€» migrations_v2 ã‚’ä½¿ç”¨ï¼ˆlegacy migrations/ ã¯å‰Šé™¤æ¸ˆã¿ï¼‰
## ============================================================
al-dump-schema-current:
	@echo "[info] Dumping current schema to sql_current/schema_head.sql"
	@bash scripts/db/dump_schema_current.sh

al-init-from-schema:
	@echo "[info] Initializing database from schema_head.sql (local_dev)"
	@if [ ! -f app/backend/core_api/migrations/alembic/sql_current/schema_head.sql ]; then \
	  echo "[error] schema_head.sql not found. Run 'make al-dump-schema-current' first."; \
	  exit 1; \
	fi
	docker compose -f docker/docker-compose.dev.yml -p local_dev \
	  exec -T db psql -U myuser -d sanbou_dev \
	  < app/backend/core_api/migrations/alembic/sql_current/schema_head.sql
	@echo "[ok] Schema initialized. Now run: make al-stamp REV=<HEAD_REVISION>"

## ============================================================
## Alembic v2: Advanced DB Management (Baseline-first)
## ============================================================
## âš ï¸ æ³¨æ„:
##   - migrations_v2 ãŒæ¨™æº–ã«ãªã‚Šã¾ã—ãŸï¼ˆlegacy migrations/ ã¯å‰Šé™¤æ¸ˆã¿ï¼‰
##   - é€šå¸¸ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¯ al-up-env / al-cur-env ãªã©ã‚’ä½¿ç”¨
##   - ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ç‰¹æ®Šæ“ä½œï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆé©ç”¨ãªã©ï¼‰ã®ã¿
##
## æ–°è¦ç’°å¢ƒæ§‹ç¯‰ï¼ˆã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‹ã‚‰ï¼‰:
##   1. make db-apply-snapshot-v2-env ENV=vm_stg
##   2. make db-bootstrap-roles-env ENV=vm_stg
##   3. make al-stamp-v2-env ENV=vm_stg REV=0001_baseline
##   4. make al-up-v2-env ENV=vm_stg
##
## é€šå¸¸ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:
##   make al-up-env ENV=local_dev   # migrations_v2 ã‚’ä½¿ç”¨
##   make al-cur-env ENV=vm_stg     # migrations_v2 ã‚’ä½¿ç”¨
##
## æ³¨æ„:
##   - vm_prod ã®åˆæœŸåŒ–ã«ã¯ FORCE=1 ãŒå¿…é ˆï¼ˆèª¤æ“ä½œé˜²æ­¢ï¼‰
## ============================================================

ALEMBIC_V2_INI ?= /backend/migrations_v2/alembic.ini
ALEMBIC_V2_ENV := $(DC_FULL) exec core_api alembic -c $(ALEMBIC_V2_INI)
BASELINE_SQL   := app/backend/core_api/migrations_v2/sql/schema_baseline.sql

.PHONY: al-up-v2-env al-down-v2-env al-cur-v2-env al-hist-v2-env al-heads-v2-env al-stamp-v2-env \
        db-apply-snapshot-v2-env db-init-from-snapshot-v2-env db-reset-volume-v2-env \
        al-up-env-legacy al-down-env-legacy al-cur-env-legacy

## v2 Alembic ã‚³ãƒãƒ³ãƒ‰ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹å­˜ã€æ¨™æº–ã‚³ãƒãƒ³ãƒ‰ã¸ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰
al-up-v2-env: al-up-env
	@echo "[éæ¨å¥¨] al-up-v2-env ã¯éæ¨å¥¨ã§ã™ã€‚make al-up-env ENV=$(ENV) ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"

al-down-v2-env: al-down-env
	@echo "[éæ¨å¥¨] al-down-v2-env ã¯éæ¨å¥¨ã§ã™ã€‚make al-down-env ENV=$(ENV) ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"

al-cur-v2-env: al-cur-env
	@echo "[éæ¨å¥¨] al-cur-v2-env ã¯éæ¨å¥¨ã§ã™ã€‚make al-cur-env ENV=$(ENV) ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"

al-hist-v2-env: al-hist-env
	@echo "[éæ¨å¥¨] al-hist-v2-env ã¯éæ¨å¥¨ã§ã™ã€‚make al-hist-env ENV=$(ENV) ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"

al-heads-v2-env: al-heads-env
	@echo "[éæ¨å¥¨] al-heads-v2-env ã¯éæ¨å¥¨ã§ã™ã€‚make al-heads-env ENV=$(ENV) ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"

al-stamp-v2-env: check
	@echo "[éæ¨å¥¨] al-stamp-v2-env ã¯éæ¨å¥¨ã§ã™ã€‚make al-stamp-env ENV=$(ENV) REV=$(REV) ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„"
	@if [ -z "$(REV)" ]; then \
	  echo "[error] REV is required. Usage: make al-stamp-env ENV=$(ENV) REV=0001_baseline"; \
	  exit 1; \
	fi
	$(ALEMBIC_ENV) stamp $(REV)
	@echo "[ok] Stamped $(ENV) database with revision $(REV)"

## ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆé©ç”¨ï¼ˆENVè¿½å¾“ã€å±é™ºæ“ä½œã‚¬ãƒ¼ãƒ‰ä»˜ãï¼‰
db-apply-snapshot-v2-env: check
	@if [ "$(ENV_CANON)" = "vm_prod" ] && [ "$(FORCE)" != "1" ]; then \
	  echo "[error] âŒ vm_prod ã¸ã® snapshot é©ç”¨ã«ã¯ FORCE=1 ãŒå¿…é ˆã§ã™"; \
	  echo "[error]    ä¾‹: make db-apply-snapshot-v2-env ENV=vm_prod FORCE=1"; \
	  exit 1; \
	fi
	@if [ ! -f "$(BASELINE_SQL)" ]; then \
	  echo "[error] âŒ Baseline SQL not found: $(BASELINE_SQL)"; \
	  echo "[error]    Run: ./scripts/db/export_schema_baseline_local_dev.sh"; \
	  exit 1; \
	fi
	@echo "[info] Applying schema baseline to $(ENV) ($(ENV_CANON))..."
	@echo "[info] Copying SQL to container..."
	$(DC_FULL) cp $(BASELINE_SQL) db:/tmp/schema_baseline.sql
	@echo "[info] Executing baseline SQL..."
	$(DC_FULL) exec -T db sh -c '\
	  psql -U "$$POSTGRES_USER" -d "$${POSTGRES_DB:-postgres}" \
	       -v ON_ERROR_STOP=1 \
	       -f /tmp/schema_baseline.sql'
	@echo "[info] Cleaning up temporary file..."
	$(DC_FULL) exec -T db rm -f /tmp/schema_baseline.sql
	@echo "[ok] Schema baseline applied successfully to $(ENV)"

## ã¾ã¨ã‚ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: DBåˆæœŸåŒ– â†’ snapshoté©ç”¨ â†’ roles bootstrap â†’ stamp
db-init-from-snapshot-v2-env: check
	@if [ "$(ENV_CANON)" = "vm_prod" ] && [ "$(FORCE)" != "1" ]; then \
	  echo "[error] âŒ vm_prod ã®åˆæœŸåŒ–ã«ã¯ FORCE=1 ãŒå¿…é ˆã§ã™"; \
	  echo "[error]    ä¾‹: make db-init-from-snapshot-v2-env ENV=vm_prod FORCE=1"; \
	  exit 1; \
	fi
	@echo "[info] ========================================"
	@echo "[info] DBåˆæœŸåŒ–ãƒ•ãƒ­ãƒ¼é–‹å§‹ (ENV=$(ENV))"
	@echo "[info] ========================================"
	@echo "[info] Step 1/5: ç’°å¢ƒåœæ­¢..."
	@$(MAKE) down ENV=$(ENV)
	@echo "[info] Step 2/5: DBãƒœãƒªãƒ¥ãƒ¼ãƒ å‰Šé™¤..."
	@$(MAKE) db-reset-volume-v2-env ENV=$(ENV) FORCE=$(FORCE)
	@echo "[info] Step 3/5: ç’°å¢ƒèµ·å‹•..."
	@$(MAKE) up ENV=$(ENV)
	@echo "[info] Step 4/5: ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆé©ç”¨..."
	@$(MAKE) db-apply-snapshot-v2-env ENV=$(ENV) FORCE=$(FORCE)
	@echo "[info] Step 5/5: Roles bootstrap..."
	@$(MAKE) db-bootstrap-roles-env ENV=$(ENV)
	@echo "[ok] ========================================"
	@echo "[ok] DBåˆæœŸåŒ–å®Œäº†ã€‚æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:"
	@echo "[ok]   make al-stamp-v2-env ENV=$(ENV) REV=0001_baseline"
	@echo "[ok]   make al-up-v2-env ENV=$(ENV)"
	@echo "[ok] ========================================"

## å±é™ºæ“ä½œ: DBãƒœãƒªãƒ¥ãƒ¼ãƒ å‰Šé™¤ï¼ˆvm_prodã¯FORCEå¿…é ˆï¼‰
db-reset-volume-v2-env:
	@if [ "$(ENV_CANON)" = "vm_prod" ] && [ "$(FORCE)" != "1" ]; then \
	  echo "[error] âŒ vm_prod ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ å‰Šé™¤ã«ã¯ FORCE=1 ãŒå¿…é ˆã§ã™"; \
	  echo "[error]    ä¾‹: make db-reset-volume-v2-env ENV=vm_prod FORCE=1"; \
	  exit 1; \
	fi
	@echo "[warning] âš ï¸  Removing postgres volume for $(ENV)..."
	docker volume rm $(ENV)_postgres_data || true
	@echo "[ok] Volume removed (if it existed)"

## ============================================================
## Legacy Alembic Commandsï¼ˆå‰Šé™¤æ¸ˆã¿ migrations/ ã¸ã®å‚ç…§ï¼‰
## ============================================================
## æ³¨æ„:
##   - legacy migrations/ ãƒ•ã‚©ãƒ«ãƒ€ã¯å®Œå…¨ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸ
##   - ã“ã‚Œã‚‰ã®ã‚³ãƒãƒ³ãƒ‰ã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ã®ã¿ã§ã™
##   - æ¨™æº–ã‚³ãƒãƒ³ãƒ‰ï¼ˆal-*-envï¼‰ãŒ migrations_v2 ã‚’ä½¿ç”¨ã—ã¾ã™
## ============================================================

al-up-env-legacy:
	@echo "âŒ [ERROR] legacy migrations/ ãƒ•ã‚©ãƒ«ãƒ€ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸ" && \
	echo "   migrations_v2 ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„: make al-up-env ENV=$(ENV)" && \
	exit 1

al-down-env-legacy:
	@echo "âŒ [ERROR] legacy migrations/ ãƒ•ã‚©ãƒ«ãƒ€ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸ" && \
	echo "   migrations_v2 ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„: make al-down-env ENV=$(ENV)" && \
	exit 1

al-cur-env-legacy:
	@echo "âŒ [ERROR] legacy migrations/ ãƒ•ã‚©ãƒ«ãƒ€ã¯å‰Šé™¤ã•ã‚Œã¾ã—ãŸ" && \
	echo "   migrations_v2 ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„: make al-cur-env ENV=$(ENV)" && \
	exit 1

## ============================================================
## Artifact Registry è¨­å®š (STG / PROD å…±é€š)
##   - ãƒ­ãƒ¼ã‚«ãƒ«PCã§ build / push ã™ã‚‹ãŸã‚ã®è¨­å®š
##   - STG: --target stg ã§ãƒ“ãƒ«ãƒ‰
##   - PROD: --target prod ã§ãƒ“ãƒ«ãƒ‰
## ============================================================

# STG è¨­å®š
STG_REGION         ?= asia-northeast1
STG_PROJECT_ID     ?= honest-sanbou-app-stg
STG_ARTIFACT_REPO  ?= sanbou-app
STG_IMAGE_REGISTRY := $(STG_REGION)-docker.pkg.dev/$(STG_PROJECT_ID)/$(STG_ARTIFACT_REPO)
STG_IMAGE_TAG      ?= stg-latest
# å¾Œæ–¹äº’æ›: æ˜”ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ IMAGE_TAG ã‚’ä½¿ã£ã¦ã„ã‚‹å ´åˆã«å¯¾å¿œï¼ˆSTG å´ï¼‰
ifdef IMAGE_TAG
  STG_IMAGE_TAG := $(IMAGE_TAG)
endif

# PROD è¨­å®š
PROD_REGION         ?= asia-northeast1
PROD_PROJECT_ID     ?= honest-sanbou-app-prod
PROD_ARTIFACT_REPO  ?= sanbou-app
PROD_IMAGE_REGISTRY := $(PROD_REGION)-docker.pkg.dev/$(PROD_PROJECT_ID)/$(PROD_ARTIFACT_REPO)
PROD_IMAGE_TAG      ?= prod-latest
# å¾Œæ–¹äº’æ›: IMAGE_TAG ã‚’æŒ‡å®šã—ãŸã‚‰ PROD å´ã«ã‚‚åæ˜ ï¼ˆå¿…è¦ã«å¿œã˜ã¦ä½¿ã†ï¼‰
ifdef IMAGE_TAG
  PROD_IMAGE_TAG := $(IMAGE_TAG)
endif

## STG â†’ PROD æ˜‡æ ¼ç”¨ã‚¿ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ stg-latest â†’ prod-latestï¼‰
PROMOTE_SRC_TAG ?= stg-latest
PROMOTE_DST_TAG ?= prod-latest

## ------------------------------------------------------------
## gcloud èªè¨¼ï¼ˆSTG / PROD å…±é€šï¼‰
##   - ä¸€åº¦ã ã‘å®Ÿè¡Œã—ã¦ãŠã‘ã° OK
##   - gcloud auth login / config set project ã¯äº‹å‰ã«å®Ÿæ–½ã—ã¦ãŠãã“ã¨
## ------------------------------------------------------------
.PHONY: gcloud-auth-docker
gcloud-auth-docker:
	@gcloud auth configure-docker $(STG_REGION)-docker.pkg.dev
	@gcloud auth configure-docker $(PROD_REGION)-docker.pkg.dev

## ============================================================
## STG ç”¨ Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ build & push
##  - ãƒ­ãƒ¼ã‚«ãƒ«PCã§å®Ÿè¡Œã™ã‚‹å‰æ
##  - VM (vm_stg) ã§ã¯ build ã›ãš pull + up ã ã‘
##  - ä½¿ã„æ–¹:
##      make publish-stg-images STG_IMAGE_TAG=stg-20251208
##      NO_CACHE=1 PULL=1 make publish-stg-images STG_IMAGE_TAG=stg-20251208
## ============================================================
.PHONY: build-stg-images push-stg-images publish-stg-images

build-stg-images:
	@echo ">>> Build STG images (tag=$(STG_IMAGE_TAG), target=stg)"
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(STG_IMAGE_REGISTRY)/core_api:$(STG_IMAGE_TAG) \
	  -f app/backend/core_api/Dockerfile --target stg app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(STG_IMAGE_REGISTRY)/plan_worker:$(STG_IMAGE_TAG) \
	  -f app/backend/plan_worker/Dockerfile --target stg app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(STG_IMAGE_REGISTRY)/inbound_forecast_worker:$(STG_IMAGE_TAG) \
	  -f app/backend/inbound_forecast_worker/Dockerfile --target stg app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(STG_IMAGE_REGISTRY)/ai_api:$(STG_IMAGE_TAG) \
	  -f app/backend/ai_api/Dockerfile --target stg app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(STG_IMAGE_REGISTRY)/ledger_api:$(STG_IMAGE_TAG) \
	  -f app/backend/ledger_api/Dockerfile --target stg app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(STG_IMAGE_REGISTRY)/rag_api:$(STG_IMAGE_TAG) \
	  -f app/backend/rag_api/Dockerfile --target stg app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(STG_IMAGE_REGISTRY)/manual_api:$(STG_IMAGE_TAG) \
	  -f app/backend/manual_api/Dockerfile --target stg app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(STG_IMAGE_REGISTRY)/nginx:$(STG_IMAGE_TAG) \
	  -f app/frontend/Dockerfile --target stg app/frontend

push-stg-images:
	@echo ">>> Push STG images (tag=$(STG_IMAGE_TAG))"
	@for svc in core_api plan_worker ai_api ledger_api rag_api manual_api nginx; do \
	  echo "  -> push $(STG_IMAGE_REGISTRY)/$$svc:$(STG_IMAGE_TAG)"; \
	  docker push $(STG_IMAGE_REGISTRY)/$$svc:$(STG_IMAGE_TAG); \
	done

publish-stg-images: build-stg-images push-stg-images
	@echo "[ok] STG images built & pushed (tag=$(STG_IMAGE_TAG))"

## ============================================================
## PROD ç”¨ Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ build & push
##  - ãƒ­ãƒ¼ã‚«ãƒ«PCã§å®Ÿè¡Œã™ã‚‹å‰æ
##  - VM (vm_prod) ã§ã¯ build ã›ãš pull + up ã ã‘
##  - ä½¿ã„æ–¹:
##      make publish-prod-images PROD_IMAGE_TAG=prod-20251209
##      NO_CACHE=1 PULL=1 make publish-prod-images PROD_IMAGE_TAG=prod-20251209
## ============================================================
.PHONY: build-prod-images push-prod-images publish-prod-images

build-prod-images:
	@echo ">>> Build PROD images (tag=$(PROD_IMAGE_TAG), target=prod)"
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(PROD_IMAGE_REGISTRY)/core_api:$(PROD_IMAGE_TAG) \
	  -f app/backend/core_api/Dockerfile --target prod app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(PROD_IMAGE_REGISTRY)/plan_worker:$(PROD_IMAGE_TAG) \
	  -f app/backend/plan_worker/Dockerfile --target prod app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(PROD_IMAGE_REGISTRY)/inbound_forecast_worker:$(PROD_IMAGE_TAG) \
	  -f app/backend/inbound_forecast_worker/Dockerfile --target prod app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(PROD_IMAGE_REGISTRY)/ai_api:$(PROD_IMAGE_TAG) \
	  -f app/backend/ai_api/Dockerfile --target prod app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(PROD_IMAGE_REGISTRY)/ledger_api:$(PROD_IMAGE_TAG) \
	  -f app/backend/ledger_api/Dockerfile --target prod app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(PROD_IMAGE_REGISTRY)/rag_api:$(PROD_IMAGE_TAG) \
	  -f app/backend/rag_api/Dockerfile --target prod app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(PROD_IMAGE_REGISTRY)/manual_api:$(PROD_IMAGE_TAG) \
	  -f app/backend/manual_api/Dockerfile --target prod app/backend
	docker build $(BUILD_PULL_FLAG) $(BUILD_NO_CACHE_FLAG) \
	  -t $(PROD_IMAGE_REGISTRY)/nginx:$(PROD_IMAGE_TAG) \
	  -f app/frontend/Dockerfile --target prod app/frontend

push-prod-images:
	@echo ">>> Push PROD images (tag=$(PROD_IMAGE_TAG))"
	@for svc in core_api plan_worker inbound_forecast_worker ai_api ledger_api rag_api manual_api nginx; do \
	  echo "  -> push $(PROD_IMAGE_REGISTRY)/$$svc:$(PROD_IMAGE_TAG)"; \
	  docker push $(PROD_IMAGE_REGISTRY)/$$svc:$(PROD_IMAGE_TAG); \
	done

publish-prod-images: build-prod-images push-prod-images
	@echo "[ok] PROD images built & pushed (tag=$(PROD_IMAGE_TAG))"

## ============================================================
## Git ref (tag/commit) ã‹ã‚‰ checkout ã›ãšã« build & push ã™ã‚‹
##   - git worktree ã‚’ä¸€æ™‚ä½œæˆã—ã¦ã€ãã®ä¸­ã§æ—¢å­˜ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’å®Ÿè¡Œ
##   - ä½¿ã„æ–¹ï¼ˆä¾‹ï¼‰:
##       NO_CACHE=1 PULL=1 make publish-stg-images-from-ref GIT_REF=v1.2.3
##       NO_CACHE=1 PULL=1 make publish-stg-images-from-ref GIT_REF=3ef33710 STG_IMAGE_TAG=stg-latest
##       NO_CACHE=1 PULL=1 make publish-prod-images-from-ref GIT_REF=v1.2.3
## ============================================================

.PHONY: publish-stg-images-from-ref publish-prod-images-from-ref

# ä¸€æ™‚worktreeã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ï¼‰
WORKTREE_TMP_BASE ?= /tmp/sanbou_worktree

publish-stg-images-from-ref:
	@if [ -z "$(GIT_REF)" ]; then \
	  echo "[error] GIT_REF is required. e.g. make $@ GIT_REF=v1.2.3"; \
	  exit 1; \
	fi
	@bash -c 'set -euo pipefail; \
	mkdir -p "$(WORKTREE_TMP_BASE)"; \
	WT_DIR="$$(mktemp -d $(WORKTREE_TMP_BASE)/stg_build_XXXXXX)"; \
	cleanup() { \
	  echo "[info] cleanup worktree $$WT_DIR"; \
	  git -C "$(CURDIR)" worktree remove -f "$$WT_DIR" >/dev/null 2>&1 || true; \
	  rm -rf "$$WT_DIR" >/dev/null 2>&1 || true; \
	}; \
	trap cleanup EXIT; \
	echo "[info] fetch tags..."; \
	git -C "$(CURDIR)" fetch --tags --prune; \
	echo "[info] create worktree: ref=$(GIT_REF) dir=$$WT_DIR"; \
	git -C "$(CURDIR)" worktree add --detach "$$WT_DIR" "$(GIT_REF)"; \
	DEFAULT_TAG="stg-$$(echo "$(GIT_REF)" | tr "/:@" "---")"; \
	TAG_TO_USE="$${STG_IMAGE_TAG:-$$DEFAULT_TAG}"; \
	echo "[info] build&push STG from ref=$(GIT_REF) tag=$$TAG_TO_USE"; \
	( cd "$$WT_DIR" && \
	  NO_CACHE="$(NO_CACHE)" PULL="$(PULL)" \
	  $(MAKE) --no-print-directory publish-stg-images STG_IMAGE_TAG="$$TAG_TO_USE" \
	); \
	echo "[ok] publish-stg-images-from-ref done (ref=$(GIT_REF), tag=$$TAG_TO_USE)"'

publish-prod-images-from-ref:
	@if [ -z "$(GIT_REF)" ]; then \
	  echo "[error] GIT_REF is required. e.g. make $@ GIT_REF=v1.2.3"; \
	  exit 1; \
	fi
	@bash -c 'set -euo pipefail; \
	mkdir -p "$(WORKTREE_TMP_BASE)"; \
	WT_DIR="$$(mktemp -d $(WORKTREE_TMP_BASE)/prod_build_XXXXXX)"; \
	cleanup() { \
	  echo "[info] cleanup worktree $$WT_DIR"; \
	  git -C "$(CURDIR)" worktree remove -f "$$WT_DIR" >/dev/null 2>&1 || true; \
	  rm -rf "$$WT_DIR" >/dev/null 2>&1 || true; \
	}; \
	trap cleanup EXIT; \
	echo "[info] fetch tags..."; \
	git -C "$(CURDIR)" fetch --tags --prune; \
	echo "[info] create worktree: ref=$(GIT_REF) dir=$$WT_DIR"; \
	git -C "$(CURDIR)" worktree add --detach "$$WT_DIR" "$(GIT_REF)"; \
	DEFAULT_TAG="prod-$$(echo "$(GIT_REF)" | tr "/:@" "---")"; \
	TAG_TO_USE="$${PROD_IMAGE_TAG:-$$DEFAULT_TAG}"; \
	echo "[info] build&push PROD from ref=$(GIT_REF) tag=$$TAG_TO_USE"; \
	( cd "$$WT_DIR" && \
	  NO_CACHE="$(NO_CACHE)" PULL="$(PULL)" \
	  $(MAKE) --no-print-directory publish-prod-images PROD_IMAGE_TAG="$$TAG_TO_USE" \
	); \
	echo "[ok] publish-prod-images-from-ref done (ref=$(GIT_REF), tag=$$TAG_TO_USE)"'

## ============================================================
## STG â†’ PROD ã‚¤ãƒ¡ãƒ¼ã‚¸æ˜‡æ ¼ï¼ˆåˆ¥ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ Artifact Registry ã‚³ãƒ”ãƒ¼ï¼‰
##   ä½¿ã„æ–¹:
##     make promote-stg-to-prod PROMOTE_SRC_TAG=stg-20251209 PROMOTE_DST_TAG=prod-20251209
##   å®Ÿè£…:
##     docker pull (STG) â†’ docker tag (PRODå) â†’ docker push (PROD)
## ============================================================
.PHONY: promote-stg-to-prod

promote-stg-to-prod:
	@echo "[info] Promote images from STG to PROD (docker pull/tag/push)"
	@echo "[info]   STG:  $(STG_IMAGE_REGISTRY):$(PROMOTE_SRC_TAG)"
	@echo "[info]   PROD: $(PROD_IMAGE_REGISTRY):$(PROMOTE_DST_TAG)"
	@for svc in core_api plan_worker inbound_forecast_worker ai_api ledger_api rag_api manual_api nginx; do \
	  SRC_IMG="$(STG_IMAGE_REGISTRY)/$$svc:$(PROMOTE_SRC_TAG)"; \
	  DST_IMG="$(PROD_IMAGE_REGISTRY)/$$svc:$(PROMOTE_DST_TAG)"; \
	  echo "  -> copy $$svc: $(PROMOTE_SRC_TAG) -> $(PROMOTE_DST_TAG)"; \
	  echo "     SRC=$$SRC_IMG"; \
	  echo "     DST=$$DST_IMG"; \
	  docker pull $$SRC_IMG; \
	  docker tag  $$SRC_IMG $$DST_IMG; \
	  docker push $$DST_IMG; \
	done
	@echo "[ok] promoted STG tag '$(PROMOTE_SRC_TAG)' to PROD tag '$(PROMOTE_DST_TAG)' (via docker)"

## ============================================================
## ã‚¤ãƒ¡ãƒ¼ã‚¸å­˜åœ¨ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
## ============================================================
.PHONY: check-stg-images check-prod-images

check-stg-images:
	@echo "[info] Checking STG images (tag=$(STG_IMAGE_TAG))"
	@for svc in core_api plan_worker ai_api ledger_api rag_api manual_api nginx; do \
	  echo "  -> checking $(STG_IMAGE_REGISTRY)/$$svc:$(STG_IMAGE_TAG)"; \
	  gcloud artifacts docker images list $(STG_REGION)-docker.pkg.dev/$(STG_PROJECT_ID)/$(STG_ARTIFACT_REPO) \
	    --filter="package=$$svc AND tags:$(STG_IMAGE_TAG)" --format="table(package,tags)" || true; \
	done

check-prod-images:
	@echo "[info] Checking PROD images (tag=$(PROD_IMAGE_TAG))"
	@for svc in core_api plan_worker ai_api ledger_api rag_api manual_api nginx; do \
	  echo "  -> checking $(PROD_IMAGE_REGISTRY)/$$svc:$(PROD_IMAGE_TAG)"; \
	  gcloud artifacts docker images list $(PROD_REGION)-docker.pkg.dev/$(PROD_PROJECT_ID)/$(PROD_ARTIFACT_REPO) \
	    --filter="package=$$svc AND tags:$(PROD_IMAGE_TAG)" --format="table(package,tags)" || true; \
	done

## ============================================================
## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆTrivyï¼‰
## ============================================================
.PHONY: scan-images scan-local-images install-trivy security-check \
        scan-stg-images scan-prod-images

# Trivy ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèªãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
install-trivy:
	@echo "=== Checking Trivy installation ==="
	@if ! command -v trivy &> /dev/null; then \
	  echo "Trivy not found. Installing..."; \
	  if [ "$$(uname)" = "Darwin" ]; then \
	    brew install aquasecurity/trivy/trivy; \
	  elif [ "$$(uname)" = "Linux" ]; then \
	    wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -; \
	    echo "deb https://aquasecurity.github.io/trivy-repo/deb $$(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list; \
	    sudo apt-get update && sudo apt-get install trivy; \
	  else \
	    echo "Unsupported OS. Please install Trivy manually: https://aquasecurity.github.io/trivy/"; \
	    exit 1; \
	  fi; \
	else \
	  echo "âœ… Trivy is already installed ($$(trivy --version))"; \
	fi

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ“ãƒ«ãƒ‰æ¸ˆã¿ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ã‚¹ã‚­ãƒ£ãƒ³
scan-local-images: install-trivy
	@echo "=== Scanning local Docker images for vulnerabilities ==="
	@SERVICES="frontend core_api ai_api ledger_api rag_api manual_api plan_worker"; \
	for svc in $$SERVICES; do \
	  IMAGE_NAME="local_dev-$$svc"; \
	  if docker images | grep -q "$$IMAGE_NAME"; then \
	    echo ""; \
	    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"; \
	    echo "Scanning: $$IMAGE_NAME"; \
	    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"; \
	    trivy image --severity HIGH,CRITICAL --exit-code 0 $$IMAGE_NAME || true; \
	  else \
	    echo "âš ï¸  Image not found: $$IMAGE_NAME (skipping)"; \
	  fi; \
	done
	@echo ""
	@echo "âœ… Scan completed. Review HIGH/CRITICAL vulnerabilities above."

# Artifact Registry ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆSTGï¼‰
scan-stg-images: install-trivy
	@echo "=== Scanning STG images in Artifact Registry ==="
	@SERVICES="core_api plan_worker ai_api ledger_api rag_api manual_api nginx"; \
	for svc in $$SERVICES; do \
	  IMAGE="$(STG_IMAGE_REGISTRY)/$$svc:$(STG_IMAGE_TAG)"; \
	  echo ""; \
	  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"; \
	  echo "Scanning: $$IMAGE"; \
	  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"; \
	  trivy image --severity HIGH,CRITICAL --exit-code 1 $$IMAGE || \
	    (echo "âŒ Vulnerabilities found in $$IMAGE"; exit 1); \
	done
	@echo "âœ… All STG images passed security scan"

# Artifact Registry ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆPRODï¼‰
scan-prod-images: install-trivy
	@echo "=== Scanning PROD images in Artifact Registry ==="
	@SERVICES="core_api plan_worker ai_api ledger_api rag_api manual_api nginx"; \
	for svc in $$SERVICES; do \
	  IMAGE="$(PROD_IMAGE_REGISTRY)/$$svc:$(PROD_IMAGE_TAG)"; \
	  echo ""; \
	  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"; \
	  echo "Scanning: $$IMAGE"; \
	  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"; \
	  trivy image --severity HIGH,CRITICAL --exit-code 1 $$IMAGE || \
	    (echo "âŒ Vulnerabilities found in $$IMAGE"; exit 1); \
	done
	@echo "âœ… All PROD images passed security scan"

# ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ï¼‰
scan-images: scan-local-images

# CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ç”¨ã®ç·åˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
security-check: scan-local-images
	@echo ""
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
	@echo "âœ… Security checks completed successfully"
	@echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

## ============================================================
## æ—¥æ¬¡äºˆæ¸¬: LookbackæœŸé–“åˆ¥ç²¾åº¦æ¯”è¼ƒå®Ÿé¨“
## ============================================================
## ä½¿ã„æ–¹:
##   make forecast-lookback-sweep END=2025-12-17
##   make forecast-lookback-sweep END=2025-12-17 QUICK=1
##   make forecast-lookback-sweep END=2025-12-17 LOOKBACKS=90,180,360
##
## ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
##   END       - è©•ä¾¡åŸºæº–æ—¥ï¼ˆå¿…é ˆã€YYYY-MM-DDå½¢å¼ï¼‰
##   LOOKBACKS - ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®lookbackæ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 60,90,120,180,270,360ï¼‰
##   QUICK     - 1ã‚’æŒ‡å®šã™ã‚‹ã¨è»½é‡ãƒ¢ãƒ¼ãƒ‰
##   EVAL_DAYS - è©•ä¾¡æœŸé–“æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 90ï¼‰
##
## å‡ºåŠ›:
##   tmp/experiments/lookback/results.csv - çµæœCSV
##   tmp/experiments/lookback/report.md   - ãƒ¬ãƒãƒ¼ãƒˆ
## ============================================================
END ?=
LOOKBACKS ?= 60,90,120,180,270,360
QUICK ?=
EVAL_DAYS ?= 90

forecast-lookback-sweep:
ifndef END
	@echo "[error] END is required. Usage: make forecast-lookback-sweep END=2025-12-17"
	@exit 1
endif
	@echo "=== Running Lookback Sweep Experiment ==="
	@echo "END_DATE: $(END)"
	@echo "LOOKBACKS: $(LOOKBACKS)"
	@echo "QUICK: $(if $(QUICK),Yes,No)"
	$(DC_FULL) exec inbound_forecast_worker python3 /backend/scripts/experiments/run_lookback_sweep.py \
		--end-date $(END) \
		--lookbacks $(LOOKBACKS) \
		--eval-days $(EVAL_DAYS) \
		$(if $(QUICK),--quick,) \
		--db-connection-string "postgresql+psycopg://sanbou_app_dev:rwT8ovWmhwLctRNuPynH4jOoYSwXvVvc2czeGC0Zos4=@db:5432/sanbou_dev"
	@echo "=== Experiment Completed ==="
	@echo "Results: tmp/experiments/lookback/results.csv"
	@echo "Report: tmp/experiments/lookback/report.md"
