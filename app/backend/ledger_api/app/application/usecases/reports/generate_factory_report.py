"""
Generate Factory Report UseCase.

å·¥å ´æ—¥å ±ç”Ÿæˆã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’æä¾›ã—ã¾ã™ã€‚

ğŸ‘¶ UseCase ã®è²¬å‹™:
1. CSV èª­ã¿è¾¼ã¿ï¼ˆPort çµŒç”±ï¼‰
2. ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆFactoryReport Entityï¼‰ã®ç”Ÿæˆ
3. ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯å‘¼ã³å‡ºã—ï¼ˆæ—¢å­˜ã® services/report/ledger/factory_report.processï¼‰
4. Excel/PDF ç”Ÿæˆ
5. ä¿å­˜ã¨ç½²åä»˜ã URL è¿”å´ï¼ˆPort çµŒç”±ï¼‰

å¤–éƒ¨ä¾å­˜ï¼ˆpandas, ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ç­‰ï¼‰ã¯ Port ã‚’é€šã—ã¦æŠ½è±¡åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚
DataFrameä¾å­˜ã¯ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ã§ç·©å’Œã—ã€å°†æ¥çš„ãªç½®ãæ›ãˆã‚’å®¹æ˜“ã«ã—ã¾ã™ã€‚
"""

import logging
import time
from datetime import date, datetime
from io import BytesIO
from pathlib import Path
import tempfile
from typing import Any, Dict, Optional

from fastapi import UploadFile
from fastapi.responses import JSONResponse

from app.core.ports.inbound import CsvGateway, ReportRepository
from app.core.ports.inbound.report_repository import ArtifactUrls
from app.core.domain.reports.factory_report import FactoryReport
from backend_shared.infra.adapters.fastapi.error_handlers import DomainError
from backend_shared.utils.date_filter_utils import (
    filter_by_period_from_min_date as shared_filter_by_period_from_min_date,
)

# æ—¢å­˜ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’å†åˆ©ç”¨ï¼ˆå°†æ¥çš„ã«ã¯ Entity ã«ç§»è¡Œï¼‰
from app.application.usecases.reports.factory_report import process as factory_report_process
from app.infra.report_utils import write_values_to_template, get_template_config
from app.infra.utils.pdf_conversion import convert_excel_to_pdf

logger = logging.getLogger(__name__)


class GenerateFactoryReportUseCase:
    """å·¥å ´æ—¥å ±ç”Ÿæˆ UseCase."""

    def __init__(
        self,
        csv_gateway: CsvGateway,
        report_repository: ReportRepository,
    ):
        """
        UseCase ã®åˆæœŸåŒ–.

        Args:
            csv_gateway: CSV èª­ã¿è¾¼ã¿ãƒ»æ¤œè¨¼ãƒ»æ•´å½¢ã®æŠ½è±¡ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
            report_repository: ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã®æŠ½è±¡ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

        ğŸ‘¶ ä¾å­˜æ€§æ³¨å…¥ï¼ˆDIï¼‰ã«ã‚ˆã‚Šã€ãƒ†ã‚¹ãƒˆæ™‚ã¯ãƒ¢ãƒƒã‚¯å®Ÿè£…ã‚’æ¸¡ã›ã¾ã™ã€‚
        """
        self.csv_gateway = csv_gateway
        self.report_repository = report_repository

    def execute(
        self,
        files: Dict[str, UploadFile],
        period_type: Optional[str] = None,
    ) -> JSONResponse:
        """
        å·¥å ´æ—¥å ±ç”Ÿæˆã®å®Ÿè¡Œ.

        Args:
            files: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ CSV ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆshipment, yard, receive ç­‰ï¼‰
            period_type: æœŸé–“æŒ‡å®šï¼ˆ"oneday" | "oneweek" | "onemonth"ï¼‰

        Returns:
            JSONResponse: ç½²åä»˜ã URL ã‚’å«ã‚€ãƒ¬ã‚¹ãƒãƒ³ã‚¹

        Raises:
            DomainError: ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«é•åã‚„å‡¦ç†å¤±æ•—æ™‚
        """
        start_time = time.time()
        file_keys = list(files.keys())
        
        logger.info(
            "å·¥å ´æ—¥å ±ç”Ÿæˆé–‹å§‹",
            extra={
                "usecase": "GenerateFactoryReportUseCase",
                "file_keys": file_keys,
                "period_type": period_type,
            },
        )

        try:
            # Step 1: CSV èª­ã¿è¾¼ã¿ï¼ˆPort çµŒç”±ï¼‰
            step_start = time.time()
            logger.debug("Step 1: CSVèª­ã¿è¾¼ã¿é–‹å§‹", extra={"file_keys": file_keys})
            
            dfs, error = self.csv_gateway.read_csv_files(files)
            if error:
                logger.warning(
                    "Step 1: CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼",
                    extra={"error_type": type(error).__name__},
                )
                return error.to_json_response()

            assert dfs is not None
            logger.debug(
                "Step 1: CSVèª­ã¿è¾¼ã¿å®Œäº†",
                extra={"elapsed_seconds": round(time.time() - step_start, 3)},
            )

            # Step 2: æ¤œè¨¼ï¼ˆPort çµŒç”±ï¼‰
            step_start = time.time()
            logger.debug("Step 2: CSVæ¤œè¨¼é–‹å§‹")
            
            validation_error = self.csv_gateway.validate_csv_structure(dfs, files)
            if validation_error:
                logger.warning("Step 2: CSVæ¤œè¨¼ã‚¨ãƒ©ãƒ¼")
                return validation_error.to_json_response()
            
            logger.debug(
                "Step 2: CSVæ¤œè¨¼å®Œäº†",
                extra={"elapsed_seconds": round(time.time() - step_start, 3)},
            )

            # Step 2.5: æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if period_type:
                step_start = time.time()
                logger.debug(
                    "Step 2.5: æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨é–‹å§‹",
                    extra={"period_type": period_type},
                )
                try:
                    dfs = shared_filter_by_period_from_min_date(dfs, period_type)
                    logger.debug(
                        "Step 2.5: æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿å®Œäº†",
                        extra={
                            "period_type": period_type,
                            "elapsed_seconds": round(time.time() - step_start, 3),
                        },
                    )
                except Exception as e:
                    logger.warning(
                        "Step 2.5: æœŸé–“ãƒ•ã‚£ãƒ«ã‚¿ã‚¹ã‚­ãƒƒãƒ—ï¼ˆã‚¨ãƒ©ãƒ¼ï¼‰",
                        extra={"exception": str(e)},
                    )

            # Step 3: æ•´å½¢ï¼ˆPort çµŒç”±ï¼‰
            step_start = time.time()
            logger.debug("Step 3: CSVæ•´å½¢é–‹å§‹")
            
            try:
                df_formatted = self.csv_gateway.format_csv_data(dfs)
                logger.debug(
                    "Step 3: CSVæ•´å½¢å®Œäº†",
                    extra={"elapsed_seconds": round(time.time() - step_start, 3)},
                )
            except DomainError:
                raise
            except Exception as ex:
                logger.error(
                    "Step 3: CSVæ•´å½¢ã‚¨ãƒ©ãƒ¼",
                    extra={"exception": str(ex)},
                    exc_info=True,
                )
                raise DomainError(
                    code="REPORT_FORMAT_ERROR",
                    status=500,
                    user_message=f"å¸³ç¥¨ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(ex)}",
                    title="ãƒ‡ãƒ¼ã‚¿æ•´å½¢ã‚¨ãƒ©ãƒ¼",
                ) from ex

            # Step 4: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ
            step_start = time.time()
            logger.debug("Step 4: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆé–‹å§‹")
            
            try:
                factory_report = FactoryReport.from_dataframes(
                    df_shipment=df_formatted.get("shipment"),
                    df_yard=df_formatted.get("yard"),
                )
                logger.info(
                    "Step 4: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆå®Œäº†",
                    extra={
                        "shipment_count": len(factory_report.shipment_items),
                        "yard_count": len(factory_report.yard_items),
                        "report_date": factory_report.report_date.isoformat(),
                        "elapsed_seconds": round(time.time() - step_start, 3),
                    },
                )
            except Exception as ex:
                logger.error(
                    "Step 4: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼",
                    extra={"exception": str(ex)},
                    exc_info=True,
                )
                raise DomainError(
                    code="DOMAIN_MODEL_ERROR",
                    status=500,
                    user_message=f"ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(ex)}",
                    title="ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼",
                ) from ex

            # Step 5: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè¡Œï¼ˆæ—¢å­˜ã® process é–¢æ•°ã‚’åˆ©ç”¨ï¼‰
            # æ³¨: ç¾æ™‚ç‚¹ã§ã¯æ—¢å­˜ã®DataFrameå‡¦ç†ã‚’ç¶­æŒã—ã€æ®µéšçš„ã«ç§»è¡Œ
            step_start = time.time()
            logger.debug("Step 5: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè¡Œé–‹å§‹")
            
            try:
                result_df = factory_report_process(df_formatted)
                logger.debug(
                    "Step 5: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè¡Œå®Œäº†",
                    extra={"elapsed_seconds": round(time.time() - step_start, 3)},
                )
            except Exception as ex:
                logger.error(
                    "Step 5: ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼",
                    extra={"exception": str(ex)},
                    exc_info=True,
                )
                raise DomainError(
                    code="REPORT_GENERATION_ERROR",
                    status=500,
                    user_message=f"å·¥å ´æ—¥å ±ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(ex)}",
                    title="ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼",
                ) from ex

            # Step 6: Excel ç”Ÿæˆ
            step_start = time.time()
            logger.debug("Step 6: Excelç”Ÿæˆé–‹å§‹")
            excel_bytes = self._generate_excel(result_df, factory_report.report_date)
            logger.debug(
                "Step 6: Excelç”Ÿæˆå®Œäº†",
                extra={
                    "size_bytes": len(excel_bytes.getvalue()),
                    "elapsed_seconds": round(time.time() - step_start, 3),
                },
            )

            # Step 7: PDF ç”Ÿæˆ
            step_start = time.time()
            logger.debug("Step 7: PDFç”Ÿæˆé–‹å§‹")
            pdf_bytes = self._generate_pdf(excel_bytes)
            logger.debug(
                "Step 7: PDFç”Ÿæˆå®Œäº†",
                extra={
                    "size_bytes": len(pdf_bytes.getvalue()),
                    "elapsed_seconds": round(time.time() - step_start, 3),
                },
            )

            # Step 8: ä¿å­˜ã¨ç½²åä»˜ã URL ç”Ÿæˆï¼ˆPort çµŒç”±ï¼‰
            step_start = time.time()
            logger.debug("Step 8: ä¿å­˜ã¨URLç”Ÿæˆé–‹å§‹")
            artifact_urls = self.report_repository.save_report(
                report_key="factory_report",
                report_date=factory_report.report_date,
                excel_bytes=excel_bytes,
                pdf_bytes=pdf_bytes,
            )
            logger.debug(
                "Step 8: ä¿å­˜ã¨URLç”Ÿæˆå®Œäº†",
                extra={"elapsed_seconds": round(time.time() - step_start, 3)},
            )

            # Step 9: ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¿”å´
            total_elapsed = time.time() - start_time
            logger.info(
                "å·¥å ´æ—¥å ±ç”Ÿæˆå®Œäº†",
                extra={
                    "usecase": "GenerateFactoryReportUseCase",
                    "report_date": factory_report.report_date.isoformat(),
                    "total_elapsed_seconds": round(total_elapsed, 3),
                },
            )
            
            # BFFäº’æ›ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼ã«å¤‰æ›
            artifact_dict = artifact_urls.to_dict()
            return JSONResponse(
                status_code=200,
                content={
                    "message": "å·¥å ´æ—¥å ±ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ",
                    "report_date": factory_report.report_date.isoformat(),
                    "artifact": {
                        "excel_download_url": artifact_dict["excel_url"],
                        "pdf_preview_url": artifact_dict["pdf_url"],
                    },
                },
            )

        except DomainError:
            # DomainError ã¯ãã®ã¾ã¾å† raise
            raise
        except Exception as ex:
            total_elapsed = time.time() - start_time
            logger.exception(
                "å·¥å ´æ—¥å ±ç”Ÿæˆä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼",
                extra={
                    "usecase": "GenerateFactoryReportUseCase",
                    "total_elapsed_seconds": round(total_elapsed, 3),
                    "exception_type": type(ex).__name__,
                    "exception_message": str(ex),
                },
            )
            raise DomainError(
                code="INTERNAL_ERROR",
                status=500,
                user_message="å·¥å ´æ—¥å ±ã®ç”Ÿæˆä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                title="å†…éƒ¨ã‚¨ãƒ©ãƒ¼",
            ) from ex

    def _extract_report_date(self, df_formatted: Dict[str, Any]) -> date:
        """
        æ•´å½¢å¾Œãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆæ—¥ä»˜ã‚’æŠ½å‡º.

        è¤‡æ•°ã®å€™è£œåˆ—ã‹ã‚‰æœ€åˆã«è¦‹ã¤ã‹ã£ãŸæœ‰åŠ¹ãªæ—¥ä»˜ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
        è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ä»Šæ—¥ã®æ—¥ä»˜ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚
        """
        if not df_formatted:
            return datetime.now().date()

        date_candidates = ["ä¼ç¥¨æ—¥ä»˜", "æ—¥ä»˜", "date", "Date"]

        for df in df_formatted.values():
            if not hasattr(df, "columns") or df.empty:
                continue

            for col in date_candidates:
                if col not in df.columns:
                    continue

                first_value = df[col].iloc[0]
                if isinstance(first_value, str):
                    try:
                        from datetime import datetime as dt
                        return dt.strptime(first_value, "%Y-%m-%d").date()
                    except (ValueError, TypeError):
                        continue
                elif hasattr(first_value, "date"):
                    return first_value.date()

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ä»Šæ—¥ã®æ—¥ä»˜
        return datetime.now().date()

    def _generate_excel(self, result_df: Any, report_date: date) -> BytesIO:
        """
        DataFrame ã‹ã‚‰ Excel ãƒã‚¤ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ç”Ÿæˆ.

        æ—¢å­˜ã® write_values_to_template ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚
        """
        template_key = "factory_report"
        template_config = get_template_config()[template_key]
        template_path = template_config["template_excel_path"]
        
        # æ—¥ä»˜æ–‡å­—åˆ—ã‚’ç”Ÿæˆï¼ˆã‚·ãƒ¼ãƒˆåç”¨ï¼‰
        extracted_date = report_date.strftime("%Yå¹´%mæœˆ%dæ—¥")

        excel_bytes = write_values_to_template(
            df=result_df,
            template_path=template_path,
            extracted_date=extracted_date,
        )

        return excel_bytes

    def _generate_pdf(self, excel_bytes: BytesIO) -> BytesIO:
        """
        Excel ãƒã‚¤ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ PDF ã‚’ç”Ÿæˆ.

        æ—¢å­˜ã® convert_excel_to_pdf ã‚’åˆ©ç”¨ã—ã¾ã™ï¼ˆä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«çµŒç”±ï¼‰ã€‚
        """
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã« Excel ã‚’æ›¸ãå‡ºã—
        with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_excel:
            tmp_excel.write(excel_bytes.getvalue())
            tmp_excel_path = Path(tmp_excel.name)

        try:
            # PDF ã«å¤‰æ›
            pdf_bytes_raw = convert_excel_to_pdf(tmp_excel_path)
            
            # BytesIO ã«ãƒ©ãƒƒãƒ—ã—ã¦è¿”å´
            pdf_bytes = BytesIO(pdf_bytes_raw)
            return pdf_bytes
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if tmp_excel_path.exists():
                tmp_excel_path.unlink()
