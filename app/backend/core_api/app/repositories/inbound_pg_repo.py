# -*- coding: utf-8 -*-
"""
Inbound repository implementation with PostgreSQL.
æ—¥æ¬¡æ¬å…¥é‡ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆCTE + ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã§ç´¯ç©è¨ˆç®—ï¼‰
"""
from datetime import date as date_type
from typing import List, Optional
import logging

from sqlalchemy import text
from sqlalchemy.orm import Session

from app.domain.ports.inbound_repository_port import InboundRepository
from app.domain.inbound import InboundDailyRow, CumScope

# ğŸ‘‡ SQLè­˜åˆ¥å­ã¯1ã‹æ‰€ã§ç®¡ç†ï¼ˆå®šæ•°åŒ–ï¼‰
from app.repositories.sql_names import V_RECEIVE_DAILY, V_CALENDAR

logger = logging.getLogger(__name__)

ALLOWED_CUM_SCOPES = {"none", "range", "month", "week"}


class InboundPgRepository(InboundRepository):
    """
    PostgreSQL implementation of InboundRepository.
    CTE + ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã§é€£ç¶šæ—¥ãƒ»0åŸ‹ã‚ãƒ»ç´¯ç©è¨ˆç®—ã‚’å®Ÿç¾
    """

    def __init__(self, db: Session):
        self.db = db

    def fetch_daily(
        self,
        start: date_type,
        end: date_type,
        segment: Optional[str] = None,
        cum_scope: CumScope = "none",
    ) -> List[InboundDailyRow]:
        """
        Fetch daily inbound data with calendar continuity and optional cumulative calculation.

        Logic:
        1. CTE 'd': ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼({V_CALENDAR})ã¨å…¥è·ãƒ“ãƒ¥ãƒ¼({V_RECEIVE_DAILY})ã‚’LEFT JOINã—ã€æ¬ ææ—¥ã‚’0åŸ‹ã‚
        2. æœ¬ä½“: cum_scopeã«å¿œã˜ã¦ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°ã§ç´¯ç©å€¤ã‚’ä»˜ä¸
        3. é€£ç¶šæ—¥ãƒ»0åŸ‹ã‚æ¸ˆã¿ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’è¿”å´

        Args:
            start: é–‹å§‹æ—¥ï¼ˆå«ã‚€ï¼‰
            end:   çµ‚äº†æ—¥ï¼ˆå«ã‚€ï¼‰
            segment: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ï¼ˆç¾çŠ¶ã“ã®ãƒ“ãƒ¥ãƒ¼ã«ã¯åˆ—ãŒç„¡ã„ãŸã‚æœªä½¿ç”¨ï¼‰
            cum_scope: ç´¯ç©ã‚¹ã‚³ãƒ¼ãƒ—ï¼ˆ"range"=å…¨æœŸé–“, "month"=æœˆã”ã¨, "week"=é€±ã”ã¨, "none"=ç´¯ç©ãªã—ï¼‰

        Returns:
            List[InboundDailyRow]

        Raises:
            ValueError: start > endã€ã¾ãŸã¯ç¯„å›²ãŒ366æ—¥ã‚’è¶…ãˆã‚‹ã€ã¾ãŸã¯cum_scopeãŒä¸æ­£
        """
        # --- Validation ---
        if start > end:
            raise ValueError(f"start ({start}) must be <= end ({end})")
        delta_days = (end - start).days + 1
        if delta_days > 366:
            raise ValueError(f"Date range exceeds 366 days: {delta_days} days")
        if cum_scope not in ALLOWED_CUM_SCOPES:
            raise ValueError(
                f"Invalid cum_scope: {cum_scope}. Must be one of {sorted(ALLOWED_CUM_SCOPES)}"
            )

        # ç¾æ™‚ç‚¹ã®v_receive_dailyã«ã¯segmentåˆ—ãŒãªã„ãŸã‚ã€å—ã‘å–ã£ã¦ã‚‚ç„¡è¦–ï¼ˆå°†æ¥å¯¾å¿œç”¨ï¼‰
        if segment is not None:
            logger.warning("segment filter is not supported on %s; ignoring segment=%r",
                           V_RECEIVE_DAILY, segment)

        # --- SQL with CTE + window function ---
        # è­˜åˆ¥å­ï¼ˆãƒ“ãƒ¥ãƒ¼åãªã©ï¼‰ã¯ f-string ã§å·®ã—è¾¼ã¿ã€å€¤ã¯ãƒã‚¤ãƒ³ãƒ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§æ¸¡ã™
        sql = text(f"""
WITH d AS (
  SELECT
    c.ddate,
    c.iso_year,
    c.iso_week,
    c.iso_dow,
    c.is_business,
    COALESCE(r.receive_net_ton, 0)::numeric AS ton
  FROM {V_CALENDAR} AS c
  LEFT JOIN {V_RECEIVE_DAILY} AS r
    ON r.ddate = c.ddate
  WHERE c.ddate BETWEEN :start AND :end
)
SELECT
  d.ddate,
  d.iso_year,
  d.iso_week,
  d.iso_dow,
  d.is_business,
  NULL::text AS segment,  -- äº’æ›ã®ãŸã‚å½¢ã ã‘è¿”ã™ï¼ˆå°†æ¥segmentå¯¾å¿œæ™‚ã«ç½®æ›ï¼‰
  d.ton,
  CASE
    WHEN :cum_scope = 'range' THEN
      SUM(d.ton) OVER (
        ORDER BY d.ddate
        ROWS UNBOUNDED PRECEDING
      )
    WHEN :cum_scope = 'month' THEN
      SUM(d.ton) OVER (
        PARTITION BY DATE_TRUNC('month', d.ddate)
        ORDER BY d.ddate
        ROWS UNBOUNDED PRECEDING
      )
    WHEN :cum_scope = 'week' THEN
      SUM(d.ton) OVER (
        PARTITION BY d.iso_year, d.iso_week
        ORDER BY d.ddate
        ROWS UNBOUNDED PRECEDING
      )
    ELSE NULL
  END AS cum_ton
FROM d
ORDER BY d.ddate
        """)

        try:
            result = self.db.execute(
                sql,
                {
                    "start": start,
                    "end": end,
                    "cum_scope": cum_scope,
                },
            )
            rows = result.fetchall()

            data: List[InboundDailyRow] = []
            for r in rows:
                # rã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã¯SELECTé †ã«å¯¾å¿œ
                ddate = r[0]
                iso_year = r[1]
                iso_week = r[2]
                iso_dow = r[3]
                is_business = r[4]
                seg = r[5]  # ç¾çŠ¶ã¯Noneç›¸å½“ã®æ–‡å­—åˆ—NULL::text
                ton = float(r[6]) if r[6] is not None else 0.0
                cum = float(r[7]) if r[7] is not None else None

                data.append(
                    InboundDailyRow(
                        ddate=ddate,
                        iso_year=iso_year,
                        iso_week=iso_week,
                        iso_dow=iso_dow,
                        is_business=is_business,
                        segment=seg,
                        ton=ton,
                        cum_ton=cum,
                    )
                )

            logger.info(
                "Fetched %d daily rows: %s to %s, segment=%s, cum_scope=%s",
                len(data), start, end, segment, cum_scope
            )
            return data

        except Exception as e:
            logger.error(
                "Failed to fetch daily inbound: %s to %s, segment=%s, cum_scope=%s, error=%s",
                start, end, segment, cum_scope, e,
                exc_info=True,
            )
            raise
