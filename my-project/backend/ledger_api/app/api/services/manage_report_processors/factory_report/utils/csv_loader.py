import pandas as pd
from typing import Dict, List, Union, Any
from app.api.services.manage_report_processors.factory_report.utils.config_loader import (
    get_required_columns_definition,
)
from app.api.services.manage_report_processors.factory_report.utils.logger import (
    app_logger,
)


def load_filtered_dataframe(
    dfs: Dict[str, pd.DataFrame],
    key: str,
    target_columns: Union[List[str], Dict[str, str]],
) -> pd.DataFrame:
    """
    æŒ‡å®šã•ã‚ŒãŸè¾æ›¸å‹DataFrameã‹ã‚‰ã€å¯¾è±¡ã‚­ãƒ¼ã®DataFrameã‚’å–å¾—ã—ã€
    æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®ã¿ã‚’æŠ½å‡ºã—ã¦è¿”ã™ã€‚

    Parameters:
        dfs (dict): è¤‡æ•°ã®DataFrameã‚’æ ¼ç´ã—ãŸè¾æ›¸ã€‚ä¾‹: {"receive": df1, "yard": df2}
        key (str): å¯¾è±¡ã¨ãªã‚‹DataFrameã®ã‚­ãƒ¼åã€‚ä¾‹: "receive"
        target_columns (list or dict): æŠ½å‡ºã™ã‚‹ã‚«ãƒ©ãƒ åã®ãƒªã‚¹ãƒˆ or {ã‚«ãƒ©ãƒ å: å‹}

    Returns:
        pd.DataFrame: æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®ã¿ã‚’æŒã¤DataFrameï¼ˆãƒ•ã‚£ãƒ«ã‚¿æ¸ˆã¿ï¼‰
    """
    logger = app_logger()

    if key not in dfs:
        raise KeyError(f"{key} ã¯dfsã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ¼: {list(dfs.keys())}")

    df = dfs[key]

    # --- å‹ä»˜ãè¾æ›¸ã ã£ãŸã‚‰ã‚­ãƒ¼ã ã‘ã‚’ä½¿ã†
    if isinstance(target_columns, dict):
        target_columns = list(target_columns.keys())

    # --- listã®ä¸­èº«ãŒã•ã‚‰ã«listãªã‚‰ flattenï¼ˆ[[...]] â†’ [...]ï¼‰
    if (
        isinstance(target_columns, list)
        and target_columns
        and isinstance(target_columns[0], list)
    ):
        target_columns = target_columns[0]

    # ã‚«ãƒ©ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    missing_cols = [col for col in target_columns if col not in df.columns]
    if missing_cols:
        logger.error(f"{key} ã«å¿…è¦ãªã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_cols}")
        logger.error(f"åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ : {list(df.columns)}")
        raise ValueError(f"{key} ã«æ¬¡ã®ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {missing_cols}")

    return df[target_columns].copy()


def flatten_list(nested_list: List[Any]) -> List[Any]:
    """
    1æ®µãƒã‚¹ãƒˆã•ã‚ŒãŸãƒªã‚¹ãƒˆã‚’ãƒ•ãƒ©ãƒƒãƒˆã«ã™ã‚‹ã€‚
    ä¾‹: [['A', 'B'], 'C'] â†’ ['A', 'B', 'C']

    Parameters:
        nested_list (list): ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒªã‚¹ãƒˆ

    Returns:
        list: ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆ
    """
    flat = []
    for item in nested_list:
        if isinstance(item, list):
            flat.extend(item)
        else:
            flat.append(item)
    return flat


def load_all_filtered_dataframes(
    dfs: Dict[str, pd.DataFrame],
    keys: List[str],
    template_name: str,
) -> Dict[str, pd.DataFrame]:
    """
    æŒ‡å®šã•ã‚ŒãŸå¸³ç¥¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨CSVã‚­ãƒ¼ã«åŸºã¥ãã€å¿…è¦ãªã‚«ãƒ©ãƒ ã®ã¿æŠ½å‡ºã—ã¦è¿”ã™ã€‚

    Parameters:
        dfs (dict): å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¾æ›¸
        keys (list): å‡¦ç†å¯¾è±¡ã®ã‚­ãƒ¼ãƒªã‚¹ãƒˆ
        template_name (str): ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå

    Returns:
        dict: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¾æ›¸
    """
    logger = app_logger()
    df_dict = {}

    try:
        column_defs = get_required_columns_definition()
        template_columns = column_defs.get(template_name, {})
        logger.info(
            f"ğŸ” å¯¾è±¡ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {template_name}, ã‚«ãƒ©ãƒ å®šç¾©: {template_columns}"
        )
    except Exception as e:
        logger.warning(f"ã‚«ãƒ©ãƒ å®šç¾©ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å…¨ã¦ã®ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨
        template_columns = {}

    for key in keys:
        if key in dfs:
            target_columns = template_columns.get(key, [])
            # ãƒã‚¹ãƒˆã•ã‚Œã¦ã„ã‚‹å ´åˆã«å‚™ãˆã¦ flatten
            if target_columns:
                target_columns = flatten_list(target_columns)
                df_dict[key] = load_filtered_dataframe(dfs, key, target_columns)
            else:
                # ã‚«ãƒ©ãƒ å®šç¾©ãŒãªã„å ´åˆã¯å…¨ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨
                logger.warning(
                    f"ã‚«ãƒ©ãƒ å®šç¾©ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å…¨ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨ã—ã¾ã™: {key}"
                )
                df_dict[key] = dfs[key].copy()
        else:
            logger.warning(f"ã‚­ãƒ¼ '{key}' ãŒdfsã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

    return df_dict
